import streamlit as st
import sqlite3
import pandas as pd
import time
import json
import base64
from supabase import create_client
import os

st.set_page_config(page_title="Migração Final SQLite → Supabase", layout="wide")

def init_supabase():
    """Inicializa o cliente Supabase"""
    try:
        url = st.secrets["SUPABASE_URL"]
        key = st.secrets["SUPABASE_KEY"]
        return create_client(url, key)
    except Exception as e:
        st.error(f"Erro ao conectar com Supabase: {e}")
        return None

def execute_sql_directly(supabase_url, supabase_key, sql_script):
    """Executa SQL diretamente no Supabase via REST API"""
    import requests
    import json
    
    headers = {
        "apikey": supabase_key,
        "Authorization": f"Bearer {supabase_key}",
        "Content-Type": "application/json",
        "Prefer": "return=minimal"
    }
    
    # Dividir o script em comandos separados para executar um por um
    commands = [cmd.strip() for cmd in sql_script.split(';') if cmd.strip()]
    
    results = []
    for cmd in commands:
        if not cmd or cmd.isspace():
            continue
            
        data = {
            "query": cmd + ";"
        }
        
        try:
            response = requests.post(
                f"{supabase_url}/rest/v1/rpc/exec_sql",
                headers=headers,
                data=json.dumps(data)
            )
            
            if response.status_code >= 300:
                st.warning(f"Aviso ao executar SQL: {response.text}")
            
            results.append({
                "command": cmd,
                "status": response.status_code,
                "response": response.text
            })
        except Exception as e:
            st.warning(f"Erro ao executar comando: {e}")
            results.append({
                "command": cmd,
                "status": "error",
                "response": str(e)
            })
    
    return results

def get_create_schema_sql():
    """Retorna o SQL para criar o schema no Supabase"""
    return """
    -- Primeiro, excluir tabelas existentes
    DROP TABLE IF EXISTS transactions CASCADE;
    DROP TABLE IF EXISTS categories CASCADE;
    DROP TABLE IF EXISTS goals CASCADE;
    DROP TABLE IF EXISTS settings CASCADE;
    DROP TABLE IF EXISTS users CASCADE;
    DROP TABLE IF EXISTS reminders CASCADE;
    DROP TABLE IF EXISTS user_settings CASCADE;

    -- Tabela de transações
    CREATE TABLE transactions (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        user_id BIGINT DEFAULT 1,
        description TEXT NOT NULL,
        amount DECIMAL(12,2) NOT NULL,
        category TEXT NOT NULL,
        date TEXT NOT NULL,
        due_date TEXT,
        type TEXT NOT NULL,
        status TEXT DEFAULT 'pendente',
        recurring BOOLEAN DEFAULT FALSE,
        priority INTEGER DEFAULT 2,
        quinzena INTEGER,
        installments INTEGER DEFAULT 1,
        current_installment INTEGER DEFAULT 1,
        fixed_expense BOOLEAN DEFAULT FALSE,
        categoria_tipo TEXT DEFAULT 'outros',
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );

    -- Tabela de categorias
    CREATE TABLE categories (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        name TEXT NOT NULL,
        type TEXT NOT NULL,
        categoria_tipo TEXT NOT NULL,
        active BOOLEAN DEFAULT TRUE
    );

    -- Tabela de metas
    CREATE TABLE goals (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        title TEXT NOT NULL,
        description TEXT,
        target_amount DECIMAL(12,2) NOT NULL,
        current_amount DECIMAL(12,2) DEFAULT 0,
        deadline TEXT,
        category TEXT,
        status TEXT DEFAULT 'Em Andamento',
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );

    -- Tabela de configurações
    CREATE TABLE settings (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        name TEXT NOT NULL UNIQUE,
        value TEXT NOT NULL
    );

    -- Tabela de usuários
    CREATE TABLE users (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        username TEXT NOT NULL UNIQUE,
        password TEXT NOT NULL,
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );

    -- Tabela de lembretes
    CREATE TABLE reminders (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        user_id BIGINT,
        transaction_id BIGINT,
        reminder_date TEXT,
        status TEXT
    );

    -- Tabela de configurações do usuário
    CREATE TABLE user_settings (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        user_id BIGINT,
        settings TEXT NOT NULL,
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );

    -- Índices para melhorar performance
    CREATE INDEX idx_transactions_user_id ON transactions(user_id);
    CREATE INDEX idx_transactions_date ON transactions(date);
    CREATE INDEX idx_transactions_category ON transactions(category);
    CREATE INDEX idx_goals_title ON goals(title);
    CREATE INDEX idx_reminders_user_id ON reminders(user_id);
    CREATE INDEX idx_reminders_transaction_id ON reminders(transaction_id);
    """

def get_all_sqlite_data(db_path):
    """Extrai todos os dados do SQLite e os prepara para inserção no Supabase"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # Obter lista de tabelas
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
    tables = [row[0] for row in cursor.fetchall()]
    
    all_data = {}
    
    for table in tables:
        # Obter estrutura da tabela
        cursor.execute(f"PRAGMA table_info({table})")
        columns = [col[1] for col in cursor.fetchall()]
        
        # Obter dados
        cursor.execute(f"SELECT * FROM {table}")
        rows = cursor.fetchall()
        
        # Converter para lista de dicionários
        table_data = []
        for row in rows:
            row_dict = {}
            for i, col in enumerate(columns):
                # Tratar valores especiais
                if isinstance(row[i], bytes):
                    # Converter bytes para base64
                    row_dict[col] = base64.b64encode(row[i]).decode('utf-8')
                elif isinstance(row[i], (bool, int)) and col in ['recurring', 'fixed_expense', 'active']:
                    # Garantir que valores booleanos sejam realmente booleanos
                    row_dict[col] = bool(row[i])
                else:
                    row_dict[col] = row[i]
            table_data.append(row_dict)
        
        all_data[table] = table_data
    
    conn.close()
    return all_data

def process_table_data(table_name, data):
    """Processa os dados de uma tabela específica para garantir compatibilidade"""
    processed_data = []
    
    for row in data:
        # Fazer uma cópia do registro
        new_row = row.copy()
        
        # Processamento específico por tabela
        if table_name == 'goals':
            # Garantir que campos obrigatórios existam
            if 'updated_at' not in new_row or new_row['updated_at'] is None:
                new_row['updated_at'] = new_row.get('created_at') or time.strftime('%Y-%m-%d %H:%M:%S')
            
            # Garantir que title não seja nulo
            if 'title' not in new_row or new_row['title'] is None:
                new_row['title'] = new_row.get('description', 'Meta sem título')
        
        # Processar campos NULL para tipos específicos
        for key, value in list(new_row.items()):
            if value is None:
                if key in ['description', 'category', 'status', 'settings']:
                    new_row[key] = ''
                elif key in ['current_amount', 'target_amount', 'amount']:
                    new_row[key] = 0.0
                elif key in ['recurring', 'fixed_expense', 'active']:
                    new_row[key] = False
                elif key in ['priority', 'installments', 'current_installment']:
                    new_row[key] = 0
        
        processed_data.append(new_row)
    
    return processed_data

def migrate_data_to_supabase(supabase, all_data):
    """Migra todos os dados para o Supabase, tabela por tabela"""
    results = {}
    
    # Definir ordem de migração para respeitar dependências
    migration_order = [
        'settings',
        'users',
        'categories',
        'transactions',
        'goals',
        'reminders',
        'user_settings'
    ]
    
    # Adicionar tabelas que não estejam na ordem específica
    for table in all_data:
        if table not in migration_order:
            migration_order.append(table)
    
    # Migrar tabelas na ordem definida
    total_tables = len(migration_order)
    
    with st.expander("Detalhes da migração", expanded=True):
        for i, table in enumerate(migration_order):
            if table not in all_data:
                st.info(f"Tabela {table} não encontrada no SQLite, pulando...")
                continue
            
            table_rows = all_data[table]
            if not table_rows:
                st.info(f"Tabela {table} está vazia, pulando...")
                continue
            
            st.write(f"Migrando tabela {table} ({len(table_rows)} registros)")
            
            # Processar dados para compatibilidade
            processed_rows = process_table_data(table, table_rows)
            
            # Primeiro limpar dados existentes
            try:
                supabase.table(table).delete().neq('id', 0).execute()
                st.write(f"✓ Tabela {table} limpa com sucesso")
            except Exception as e:
                st.warning(f"Aviso ao limpar tabela {table}: {e}")
            
            # Inserir em lotes pequenos para evitar problemas
            success = True
            error_msg = None
            batch_size = 5
            
            progress_bar = st.progress(0)
            status_placeholder = st.empty()
            
            for j in range(0, len(processed_rows), batch_size):
                batch = processed_rows[j:min(j+batch_size, len(processed_rows))]
                progress = min(1.0, (j + batch_size) / len(processed_rows))
                progress_bar.progress(progress)
                
                try:
                    response = supabase.table(table).insert(batch).execute()
                    status_placeholder.write(f"Processando lote {j//batch_size + 1}/{(len(processed_rows) + batch_size - 1)//batch_size}...")
                except Exception as e:
                    status_placeholder.write(f"⚠️ Erro no lote {j//batch_size + 1}: {e}")
                    
                    # Tentar inserir um por um para identificar registros problemáticos
                    for record in batch:
                        try:
                            supabase.table(table).insert(record).execute()
                        except Exception as item_e:
                            st.write(f"⚠️ Erro no registro ID {record.get('id', 'N/A')}: {item_e}")
                            success = False
                            error_msg = str(item_e)
            
            # Atualizar status final
            if success:
                st.success(f"✅ Tabela {table} migrada com sucesso ({len(processed_rows)} registros)")
            else:
                st.warning(f"⚠️ Tabela {table} migrada com alguns avisos: {error_msg}")
            
            # Armazenar resultado
            results[table] = {"success": success, "count": len(processed_rows), "message": error_msg}
    
    return results

def main():
    st.title("Migração Final SQLite → Supabase")
    
    st.markdown("""
    ## Migração Definitiva: SQLite → Supabase
    
    Esta ferramenta realiza uma migração completa e robusta do seu banco de dados SQLite para o Supabase,
    resolvendo todos os problemas encontrados nas tentativas anteriores.
    
    ### O que será feito:
    
    1. **Criação do schema completo** no Supabase
    2. **Extração de todos os dados** do SQLite
    3. **Migração tabela por tabela** com tratamento de erros
    
    **Atenção**: Esta operação substituirá todos os dados no Supabase.
    """)
    
    # Verificar credenciais do Supabase
    url = st.secrets.get("SUPABASE_URL", "")
    key = st.secrets.get("SUPABASE_KEY", "")
    
    if not url or not key:
        st.error("""
        ### ⚠️ Credenciais do Supabase não encontradas!
        
        Adicione as seguintes chaves ao seu arquivo `.streamlit/secrets.toml`:
        ```
        SUPABASE_URL = "sua-url-do-projeto"
        SUPABASE_KEY = "sua-chave-anon"
        ```
        """)
        return
    
    # Configurações
    with st.form("config_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            db_path = st.text_input("Caminho do banco SQLite:", "financas.db")
        
        with col2:
            make_backup = st.checkbox("Fazer backup dos dados antes da migração", value=True)
        
        submitted = st.form_submit_button("Iniciar Migração Completa")
    
    if submitted:
        st.markdown("---")
        st.subheader("Executando Migração...")
        
        # Etapa 1: Verificar conexão com Supabase
        with st.spinner("Conectando ao Supabase..."):
            supabase = init_supabase()
            if not supabase:
                st.error("❌ Falha ao conectar ao Supabase. Verifique suas credenciais.")
                return
            st.success("✅ Conexão com Supabase estabelecida")
        
        # Etapa 2: Criar schema no Supabase
        with st.spinner("Criando schema no Supabase..."):
            st.info("Criando tabelas no Supabase...")
            sql_script = get_create_schema_sql()
            
            try:
                results = execute_sql_directly(url, key, sql_script)
                st.success("✅ Schema criado com sucesso no Supabase")
                
                with st.expander("Ver detalhes do SQL executado", expanded=False):
                    for res in results:
                        st.code(res["command"])
                        st.write(f"Status: {res['status']}")
            except Exception as e:
                st.error(f"❌ Erro ao criar schema: {e}")
                return
        
        # Etapa 3: Extrair dados do SQLite
        with st.spinner("Extraindo dados do SQLite..."):
            try:
                all_data = get_all_sqlite_data(db_path)
                tables_info = {table: len(rows) for table, rows in all_data.items()}
                st.success(f"✅ Dados extraídos com sucesso: {tables_info}")
                
                # Fazer backup se solicitado
                if make_backup:
                    backup_file = f"backup_final_{time.strftime('%Y%m%d_%H%M%S')}.json"
                    with open(backup_file, "w") as f:
                        json.dump(all_data, f)
                    st.info(f"📁 Backup salvo em: {backup_file}")
            except Exception as e:
                st.error(f"❌ Erro ao extrair dados: {e}")
                return
        
        # Etapa 4: Migrar dados para Supabase
        with st.spinner("Migrando dados para Supabase..."):
            try:
                results = migrate_data_to_supabase(supabase, all_data)
                
                # Contar sucessos
                success_count = sum(1 for r in results.values() if r["success"])
                
                if success_count == len(results):
                    st.success(f"🎉 Migração concluída com sucesso! Todas as {len(results)} tabelas foram migradas.")
                else:
                    st.warning(f"⚠️ Migração concluída com alguns avisos. {success_count}/{len(results)} tabelas migradas com sucesso.")
            except Exception as e:
                st.error(f"❌ Erro durante a migração: {e}")
                return
        
        # Etapa 5: Instruções finais
        st.markdown("---")
        st.subheader("Próximos Passos")
        st.info("""
        ### O que fazer agora:
        
        1. **Execute seu aplicativo principal**:
           ```
           streamlit run run.py
           ```
           
        2. **Seu app agora usará o Supabase automaticamente** porque as credenciais estão configuradas
        
        3. **Atualize seu app no Streamlit Cloud**:
           - Atualize seu código no GitHub ou faça upload manual
           - Configure os secrets no Streamlit Cloud
           
        4. **Desfrute do acesso a seus dados de qualquer dispositivo!**
        """)

if __name__ == "__main__":
    main()
