import streamlit as st
import sqlite3
import pandas as pd
import time
import json
import base64
from supabase import create_client
import os

st.set_page_config(page_title="Migra√ß√£o Final SQLite ‚Üí Supabase", layout="wide")

def init_supabase():
    """Inicializa o cliente Supabase"""
    try:
        url = st.secrets["SUPABASE_URL"]
        key = st.secrets["SUPABASE_KEY"]
        return create_client(url, key)
    except Exception as e:
        st.error(f"Erro ao conectar com Supabase: {e}")
        return None

def execute_sql_directly(supabase_url, supabase_key, sql_script):
    """Executa SQL diretamente no Supabase via REST API"""
    import requests
    import json
    
    headers = {
        "apikey": supabase_key,
        "Authorization": f"Bearer {supabase_key}",
        "Content-Type": "application/json",
        "Prefer": "return=minimal"
    }
    
    # Dividir o script em comandos separados para executar um por um
    commands = [cmd.strip() for cmd in sql_script.split(';') if cmd.strip()]
    
    results = []
    for cmd in commands:
        if not cmd or cmd.isspace():
            continue
            
        data = {
            "query": cmd + ";"
        }
        
        try:
            response = requests.post(
                f"{supabase_url}/rest/v1/rpc/exec_sql",
                headers=headers,
                data=json.dumps(data)
            )
            
            if response.status_code >= 300:
                st.warning(f"Aviso ao executar SQL: {response.text}")
            
            results.append({
                "command": cmd,
                "status": response.status_code,
                "response": response.text
            })
        except Exception as e:
            st.warning(f"Erro ao executar comando: {e}")
            results.append({
                "command": cmd,
                "status": "error",
                "response": str(e)
            })
    
    return results

def get_create_schema_sql():
    """Retorna o SQL para criar o schema no Supabase"""
    return """
    -- Primeiro, excluir tabelas existentes
    DROP TABLE IF EXISTS transactions CASCADE;
    DROP TABLE IF EXISTS categories CASCADE;
    DROP TABLE IF EXISTS goals CASCADE;
    DROP TABLE IF EXISTS settings CASCADE;
    DROP TABLE IF EXISTS users CASCADE;
    DROP TABLE IF EXISTS reminders CASCADE;
    DROP TABLE IF EXISTS user_settings CASCADE;

    -- Tabela de transa√ß√µes
    CREATE TABLE transactions (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        user_id BIGINT DEFAULT 1,
        description TEXT NOT NULL,
        amount DECIMAL(12,2) NOT NULL,
        category TEXT NOT NULL,
        date TEXT NOT NULL,
        due_date TEXT,
        type TEXT NOT NULL,
        status TEXT DEFAULT 'pendente',
        recurring BOOLEAN DEFAULT FALSE,
        priority INTEGER DEFAULT 2,
        quinzena INTEGER,
        installments INTEGER DEFAULT 1,
        current_installment INTEGER DEFAULT 1,
        fixed_expense BOOLEAN DEFAULT FALSE,
        categoria_tipo TEXT DEFAULT 'outros',
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );

    -- Tabela de categorias
    CREATE TABLE categories (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        name TEXT NOT NULL,
        type TEXT NOT NULL,
        categoria_tipo TEXT NOT NULL,
        active BOOLEAN DEFAULT TRUE
    );

    -- Tabela de metas
    CREATE TABLE goals (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        title TEXT NOT NULL,
        description TEXT,
        target_amount DECIMAL(12,2) NOT NULL,
        current_amount DECIMAL(12,2) DEFAULT 0,
        deadline TEXT,
        category TEXT,
        status TEXT DEFAULT 'Em Andamento',
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );

    -- Tabela de configura√ß√µes
    CREATE TABLE settings (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        name TEXT NOT NULL UNIQUE,
        value TEXT NOT NULL
    );

    -- Tabela de usu√°rios
    CREATE TABLE users (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        username TEXT NOT NULL UNIQUE,
        password TEXT NOT NULL,
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );

    -- Tabela de lembretes
    CREATE TABLE reminders (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        user_id BIGINT,
        transaction_id BIGINT,
        reminder_date TEXT,
        status TEXT
    );

    -- Tabela de configura√ß√µes do usu√°rio
    CREATE TABLE user_settings (
        id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
        user_id BIGINT,
        settings TEXT NOT NULL,
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );

    -- √çndices para melhorar performance
    CREATE INDEX idx_transactions_user_id ON transactions(user_id);
    CREATE INDEX idx_transactions_date ON transactions(date);
    CREATE INDEX idx_transactions_category ON transactions(category);
    CREATE INDEX idx_goals_title ON goals(title);
    CREATE INDEX idx_reminders_user_id ON reminders(user_id);
    CREATE INDEX idx_reminders_transaction_id ON reminders(transaction_id);
    """

def get_all_sqlite_data(db_path):
    """Extrai todos os dados do SQLite e os prepara para inser√ß√£o no Supabase"""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # Obter lista de tabelas
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'")
    tables = [row[0] for row in cursor.fetchall()]
    
    all_data = {}
    
    for table in tables:
        # Obter estrutura da tabela
        cursor.execute(f"PRAGMA table_info({table})")
        columns = [col[1] for col in cursor.fetchall()]
        
        # Obter dados
        cursor.execute(f"SELECT * FROM {table}")
        rows = cursor.fetchall()
        
        # Converter para lista de dicion√°rios
        table_data = []
        for row in rows:
            row_dict = {}
            for i, col in enumerate(columns):
                # Tratar valores especiais
                if isinstance(row[i], bytes):
                    # Converter bytes para base64
                    row_dict[col] = base64.b64encode(row[i]).decode('utf-8')
                elif isinstance(row[i], (bool, int)) and col in ['recurring', 'fixed_expense', 'active']:
                    # Garantir que valores booleanos sejam realmente booleanos
                    row_dict[col] = bool(row[i])
                else:
                    row_dict[col] = row[i]
            table_data.append(row_dict)
        
        all_data[table] = table_data
    
    conn.close()
    return all_data

def process_table_data(table_name, data):
    """Processa os dados de uma tabela espec√≠fica para garantir compatibilidade"""
    processed_data = []
    
    for row in data:
        # Fazer uma c√≥pia do registro
        new_row = row.copy()
        
        # Processamento espec√≠fico por tabela
        if table_name == 'goals':
            # Garantir que campos obrigat√≥rios existam
            if 'updated_at' not in new_row or new_row['updated_at'] is None:
                new_row['updated_at'] = new_row.get('created_at') or time.strftime('%Y-%m-%d %H:%M:%S')
            
            # Garantir que title n√£o seja nulo
            if 'title' not in new_row or new_row['title'] is None:
                new_row['title'] = new_row.get('description', 'Meta sem t√≠tulo')
        
        # Processar campos NULL para tipos espec√≠ficos
        for key, value in list(new_row.items()):
            if value is None:
                if key in ['description', 'category', 'status', 'settings']:
                    new_row[key] = ''
                elif key in ['current_amount', 'target_amount', 'amount']:
                    new_row[key] = 0.0
                elif key in ['recurring', 'fixed_expense', 'active']:
                    new_row[key] = False
                elif key in ['priority', 'installments', 'current_installment']:
                    new_row[key] = 0
        
        processed_data.append(new_row)
    
    return processed_data

def migrate_data_to_supabase(supabase, all_data):
    """Migra todos os dados para o Supabase, tabela por tabela"""
    results = {}
    
    # Definir ordem de migra√ß√£o para respeitar depend√™ncias
    migration_order = [
        'settings',
        'users',
        'categories',
        'transactions',
        'goals',
        'reminders',
        'user_settings'
    ]
    
    # Adicionar tabelas que n√£o estejam na ordem espec√≠fica
    for table in all_data:
        if table not in migration_order:
            migration_order.append(table)
    
    # Migrar tabelas na ordem definida
    total_tables = len(migration_order)
    
    with st.expander("Detalhes da migra√ß√£o", expanded=True):
        for i, table in enumerate(migration_order):
            if table not in all_data:
                st.info(f"Tabela {table} n√£o encontrada no SQLite, pulando...")
                continue
            
            table_rows = all_data[table]
            if not table_rows:
                st.info(f"Tabela {table} est√° vazia, pulando...")
                continue
            
            st.write(f"Migrando tabela {table} ({len(table_rows)} registros)")
            
            # Processar dados para compatibilidade
            processed_rows = process_table_data(table, table_rows)
            
            # Primeiro limpar dados existentes
            try:
                supabase.table(table).delete().neq('id', 0).execute()
                st.write(f"‚úì Tabela {table} limpa com sucesso")
            except Exception as e:
                st.warning(f"Aviso ao limpar tabela {table}: {e}")
            
            # Inserir em lotes pequenos para evitar problemas
            success = True
            error_msg = None
            batch_size = 5
            
            progress_bar = st.progress(0)
            status_placeholder = st.empty()
            
            for j in range(0, len(processed_rows), batch_size):
                batch = processed_rows[j:min(j+batch_size, len(processed_rows))]
                progress = min(1.0, (j + batch_size) / len(processed_rows))
                progress_bar.progress(progress)
                
                try:
                    response = supabase.table(table).insert(batch).execute()
                    status_placeholder.write(f"Processando lote {j//batch_size + 1}/{(len(processed_rows) + batch_size - 1)//batch_size}...")
                except Exception as e:
                    status_placeholder.write(f"‚ö†Ô∏è Erro no lote {j//batch_size + 1}: {e}")
                    
                    # Tentar inserir um por um para identificar registros problem√°ticos
                    for record in batch:
                        try:
                            supabase.table(table).insert(record).execute()
                        except Exception as item_e:
                            st.write(f"‚ö†Ô∏è Erro no registro ID {record.get('id', 'N/A')}: {item_e}")
                            success = False
                            error_msg = str(item_e)
            
            # Atualizar status final
            if success:
                st.success(f"‚úÖ Tabela {table} migrada com sucesso ({len(processed_rows)} registros)")
            else:
                st.warning(f"‚ö†Ô∏è Tabela {table} migrada com alguns avisos: {error_msg}")
            
            # Armazenar resultado
            results[table] = {"success": success, "count": len(processed_rows), "message": error_msg}
    
    return results

def main():
    st.title("Migra√ß√£o Final SQLite ‚Üí Supabase")
    
    st.markdown("""
    ## Migra√ß√£o Definitiva: SQLite ‚Üí Supabase
    
    Esta ferramenta realiza uma migra√ß√£o completa e robusta do seu banco de dados SQLite para o Supabase,
    resolvendo todos os problemas encontrados nas tentativas anteriores.
    
    ### O que ser√° feito:
    
    1. **Cria√ß√£o do schema completo** no Supabase
    2. **Extra√ß√£o de todos os dados** do SQLite
    3. **Migra√ß√£o tabela por tabela** com tratamento de erros
    
    **Aten√ß√£o**: Esta opera√ß√£o substituir√° todos os dados no Supabase.
    """)
    
    # Verificar credenciais do Supabase
    url = st.secrets.get("SUPABASE_URL", "")
    key = st.secrets.get("SUPABASE_KEY", "")
    
    if not url or not key:
        st.error("""
        ### ‚ö†Ô∏è Credenciais do Supabase n√£o encontradas!
        
        Adicione as seguintes chaves ao seu arquivo `.streamlit/secrets.toml`:
        ```
        SUPABASE_URL = "sua-url-do-projeto"
        SUPABASE_KEY = "sua-chave-anon"
        ```
        """)
        return
    
    # Configura√ß√µes
    with st.form("config_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            db_path = st.text_input("Caminho do banco SQLite:", "financas.db")
        
        with col2:
            make_backup = st.checkbox("Fazer backup dos dados antes da migra√ß√£o", value=True)
        
        submitted = st.form_submit_button("Iniciar Migra√ß√£o Completa")
    
    if submitted:
        st.markdown("---")
        st.subheader("Executando Migra√ß√£o...")
        
        # Etapa 1: Verificar conex√£o com Supabase
        with st.spinner("Conectando ao Supabase..."):
            supabase = init_supabase()
            if not supabase:
                st.error("‚ùå Falha ao conectar ao Supabase. Verifique suas credenciais.")
                return
            st.success("‚úÖ Conex√£o com Supabase estabelecida")
        
        # Etapa 2: Criar schema no Supabase
        with st.spinner("Criando schema no Supabase..."):
            st.info("Criando tabelas no Supabase...")
            sql_script = get_create_schema_sql()
            
            try:
                results = execute_sql_directly(url, key, sql_script)
                st.success("‚úÖ Schema criado com sucesso no Supabase")
                
                with st.expander("Ver detalhes do SQL executado", expanded=False):
                    for res in results:
                        st.code(res["command"])
                        st.write(f"Status: {res['status']}")
            except Exception as e:
                st.error(f"‚ùå Erro ao criar schema: {e}")
                return
        
        # Etapa 3: Extrair dados do SQLite
        with st.spinner("Extraindo dados do SQLite..."):
            try:
                all_data = get_all_sqlite_data(db_path)
                tables_info = {table: len(rows) for table, rows in all_data.items()}
                st.success(f"‚úÖ Dados extra√≠dos com sucesso: {tables_info}")
                
                # Fazer backup se solicitado
                if make_backup:
                    backup_file = f"backup_final_{time.strftime('%Y%m%d_%H%M%S')}.json"
                    with open(backup_file, "w") as f:
                        json.dump(all_data, f)
                    st.info(f"üìÅ Backup salvo em: {backup_file}")
            except Exception as e:
                st.error(f"‚ùå Erro ao extrair dados: {e}")
                return
        
        # Etapa 4: Migrar dados para Supabase
        with st.spinner("Migrando dados para Supabase..."):
            try:
                results = migrate_data_to_supabase(supabase, all_data)
                
                # Contar sucessos
                success_count = sum(1 for r in results.values() if r["success"])
                
                if success_count == len(results):
                    st.success(f"üéâ Migra√ß√£o conclu√≠da com sucesso! Todas as {len(results)} tabelas foram migradas.")
                else:
                    st.warning(f"‚ö†Ô∏è Migra√ß√£o conclu√≠da com alguns avisos. {success_count}/{len(results)} tabelas migradas com sucesso.")
            except Exception as e:
                st.error(f"‚ùå Erro durante a migra√ß√£o: {e}")
                return
        
        # Etapa 5: Instru√ß√µes finais
        st.markdown("---")
        st.subheader("Pr√≥ximos Passos")
        st.info("""
        ### O que fazer agora:
        
        1. **Execute seu aplicativo principal**:
           ```
           streamlit run run.py
           ```
           
        2. **Seu app agora usar√° o Supabase automaticamente** porque as credenciais est√£o configuradas
        
        3. **Atualize seu app no Streamlit Cloud**:
           - Atualize seu c√≥digo no GitHub ou fa√ßa upload manual
           - Configure os secrets no Streamlit Cloud
           
        4. **Desfrute do acesso a seus dados de qualquer dispositivo!**
        """)

if __name__ == "__main__":
    main()
